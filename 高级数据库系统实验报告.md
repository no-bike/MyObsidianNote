
# 学习型代价估计器：zero-shot cost models
# 1.论文阅读报告

这篇论文最重要的创新点在于提出了**零样本成本模型（Zero-Shot Cost Models）**，通过一种新型的**可迁移查询表示方法**和**图结构模型架构**，实现了在没有目标数据库训练数据的情况下，直接预测查询执行成本。以下是核心创新点的详细说明，尤其是图构造部分：

---

### **1. 零样本学习范式**
- **问题背景**：传统基于学习的成本模型（如E2E、MSCN）需要针对每个新数据库执行大量查询以收集训练数据，耗时且不实用。
- **创新**：提出零样本学习范式，通过预训练模型在多个数据库上学习通用成本模式，无需目标数据库的训练数据即可直接预测查询成本。若目标数据库有少量查询（few-shot），还可通过微调进一步提升准确性。
---

### **2. 可迁移的图结构查询表示**
这是论文的核心创新，具体体现在以下方面：

#### **(1) 图结构的查询编码**
- **传统方法**：现有工作（如E2E模型）将查询计划表示为树或向量，但特征（如列名、表名）采用独热编码（one-hot），导致模型绑定到特定数据库，无法迁移。

- **创新方法**：  
  - **多类型节点**：将查询计划表示为**有向无环图（DAG）**，包含多种节点类型（如图3所示）：![[Pasted image 20250503214303.png]]
    - **灰色节点**：物理操作符（如扫描、连接）。
    - **蓝色节点**：表（如`movie_companies`）。
    - **绿色节点**：输入列（如`company_type_id`）。
    - **红色节点**：谓词结构（如比较操作符`=`）。
  - **可迁移特征**：每个节点用**与数据库无关的特征**（如表1所列）：
  ![[Pasted image 20250503214409.png]]
    - 操作符节点：操作类型、并行工作线程数等。
    - 表节点：行数、磁盘页数等。
    - 列节点：数据类型、宽度、空值比例等。
    - 谓词节点：操作符类型（如`=`、`IN`）、字面量复杂度（如正则表达式复杂度）。

#### **(2) 特征设计的可迁移性**
- **关键思想**：所有特征均基于通用语义（如“列宽度”而非“列名”），确保模型可跨数据库泛化。
  - 例如，`company_type_id=2`的谓词被编码为“某数值列与字面量的等值比较”，而非具体列名。

#### **(3) 图神经网络（GNN）的消息传递机制**
- **三步推理流程**（算法1）：
![[Pasted image 20250503214426.png]]
  1. **节点编码**：每个节点的特征通过类型特定的MLP转换为隐藏状态（如所有扫描操作符共享同一MLP）。
  2. **自底向上消息传递**：沿查询树拓扑顺序聚合子节点信息，更新父节点状态，捕捉操作符间的交互（如流水线执行效应）。
  3. **根节点预测**：根节点的隐藏状态输入最终MLP，输出成本估计。
- **优势**：通过图结构显式建模操作符间的复杂交互，比传统扁平化向量表示更准确（图10对比）。

---

### **3. 分离关注点（Separation of Concerns）**

传统成本模型（如PostgreSQL的基于代价的优化器）通常将 **数据分布** 和 **执行引擎成本** 耦合在一起，导致模型难以适应新数据库。  
本文通过 **分离关注点** 解决该问题：

### **(1) 数据特性作为显式输入**

- **零样本模型不隐式学习数据分布**，而是依赖外部提供的特征：
    - **静态元数据**：表大小（`reltuples`）、列宽度（`width`）。
    - **动态基数估计**：每个操作符的输出行数（`card_est`），可通过以下两种方式提供：
        1. **传统优化器**（如PostgreSQL的统计信息）。
        2. **学习型基数估计器**（如DeepDB）。
- **实验验证**：
    ![[Pasted image 20250503214223.png]]
    - 使用学习型基数估计器（DeepDB）时，零样本模型接近完美基数下的性能。
    - 即使使用传统优化器的粗略估计，模型仍优于非学习型方法。

### **(2) 适应数据更新的能力**

- 当数据库更新（如表扩容）时：
    - **传统学习模型**：需重新执行查询收集训练数据（图7显示E2E模型性能下降）。
    - **零样本模型**：仅需更新输入特征（如 `reltuples` 和 `card_est`），无需重训练。

### **(3) 支持Few-Shot微调**

- 如果目标数据库有少量查询（如50个），可通过微调提升性能：
    - 在预训练模型基础上，用目标数据库的查询进一步训练。
    - 实验显示，50次微调即可显著提升准确性。
    
---

### **4. 实际应用价值**
- **训练开销大幅降低**：零样本模型仅需一次跨数据库预训练，而传统方法需为每个新数据库执行数万查询（图5显示E2E需50k查询/66小时）。
![[Pasted image 20250503214616.png]]
- 对数据更新和 workload drift具有良好适应性，可通过少量微调（few-shot）进一步提升。


---
# 2.复现与评估

GitHub仓库：https://github.com/DataManagementLab/zero-shot-cost-estimation.
根据源代码，以及详细的md文件可做复现，但由于本人电脑只有cpu所以跑了三天才跑出来一轮结果= =
未见数据库的零样本精度评估
![[Pasted image 20250518134148.png]]

![[Pasted image 20250518134159.png]]

![[Pasted image 20250518134211.png]]
跑出来的结果相对best都有一点差距。

---
# 3. 改进意见


1. 训练数据其实仍然是与硬件绑定的，或许可以通过采集不同硬件的运行数据训练来达到跨硬件的迁移。

2. 在论文中使用DAG作为输入，但实际上是直接以图为输入来进行训练。

3. 非关系型数据库是否可以通过这种思路来进行跨数据库的训练？


